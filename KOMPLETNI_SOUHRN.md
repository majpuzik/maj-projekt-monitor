# âœ“ KompletnÃ­ souhrn instalace NVIDIA Build nÃ¡strojÅ¯

**Datum dokonÄenÃ­:** 13.11.2025
**SystÃ©m:** DGX Spark GB10 (ARM64), Ubuntu, CUDA 13.0

---

## âœ… 1. RAPIDS / CUDA-X Data Science - HOTOVO

**Status:** âœ“ PlnÄ› funkÄnÃ­ a otestovÃ¡no

**UmÃ­stÄ›nÃ­:** Conda prostÅ™edÃ­ `rapids-cuda13`

**Verze:**
- cuDF: 25.10.00
- cuML: 25.10.00
- CuPy: 13.6.0
- dask-cuda: 25.10.00

**Jak pouÅ¾Ã­t:**
```bash
conda activate rapids-cuda13
python -c "import cudf; df = cudf.DataFrame({'a': [1,2,3]}); print(df)"
```

**Test probÄ›hl ÃºspÄ›Å¡nÄ›** - vÅ¡echny komponenty fungujÃ­!

---

## âœ… 2. PyTorch Fine-tune - HOTOVO

**Status:** âœ“ Container pÅ™ipraven, skripty dostupnÃ©

**Image:** `nvcr.io/nvidia/pytorch:25.09-py3` (18.1GB)

**DostupnÃ© skripty:**
- `Llama3_8B_LoRA_finetuning.py` - LoRA pro Llama 8B
- `Llama3_70B_qLoRA_finetuning.py` - qLoRA pro Llama 70B
- `Llama3_3B_full_finetuning.py` - PlnÃ½ fine-tuning Llama 3B

**Jak zaÄÃ­t:**
```bash
# PÅ™eÄtÄ›te si podrobnÃ½ nÃ¡vod:
cat ~/START_PYTORCH_FINETUNE.md

# Nebo rovnou spusÅ¥te:
cd ~
docker run --gpus all -it --rm --ipc=host \
  -v $HOME/.cache/huggingface:/root/.cache/huggingface \
  -v ${PWD}:/workspace -w /workspace \
  nvcr.io/nvidia/pytorch:25.09-py3
```

**RychlÃ½ script:** `~/run_pytorch_finetune.sh`

---

## âœ… 3. NVFP4 Quantization - HOTOVO

**Status:** âœ“ TensorRT-LLM container staÅ¾en a otestovÃ¡n

**Image:** `nvcr.io/nvidia/tensorrt-llm/release:spark-single-gpu-dev`

**Test:**
```bash
docker run --rm --gpus all \
  nvcr.io/nvidia/tensorrt-llm/release:spark-single-gpu-dev \
  nvidia-smi
```

**PoznÃ¡mka:** Pro kvantizaci modelÅ¯ nÃ¡sledujte oficiÃ¡lnÃ­ nÃ¡vod: https://build.nvidia.com/spark/nvfp4-quantization

---

## â³ 4. LM Studio - STAHOVÃNÃ

**Status:** â³ AppImage se stahuje (~28% hotovo)

**Verze:** 0.3.31 (ARM64) - OficiÃ¡lnÃ­ podpora pro DGX Spark!

**SpeciÃ¡lnÃ­ optimalizace:** CUDA 13.0, llama.cpp engine

**Po dokonÄenÃ­ stahovÃ¡nÃ­:**
```bash
# Spustit GUI
~/LMStudio-0.3.31-arm64.AppImage

# Nebo pouÅ¾Ã­t helper script
~/run_lmstudio.sh

# PÅ™eÄÃ­st podrobnÃ½ nÃ¡vod
cat ~/START_LMSTUDIO.md
```

**DoporuÄenÃ© modely:**
- Qwen 7B (Q4_K_M) - rychlÃ© testovÃ¡nÃ­
- Mistral 7B (Q4_K_M) - dobrÃ¡ kvalita
- Llama 3 70B (Q4_K_M) - vyuÅ¾ijete 128GB RAM!

**API endpoint:** `http://localhost:1234` (OpenAI-kompatibilnÃ­)

---

## âœ… 5. NeMo AutoModel - PÅ˜IPRAVENO

**Status:** âœ“ RepozitÃ¡Å™ naklonovÃ¡n

**UmÃ­stÄ›nÃ­:** `~/NeMo-Automodel`

**PoznÃ¡mka:** LokÃ¡lnÃ­ instalace selhala kvÅ¯li ARM64 kompatibilitÄ› (triton nemÃ¡ ARM64 wheel).

**Å˜eÅ¡enÃ­:** PouÅ¾Ã­t Docker

**Docker build (pÅ™ipraven):**
```bash
cd ~/NeMo-Automodel
# Dockerfile je v: ~/NeMo-Automodel/docker/Dockerfile
# PouÅ¾Ã­vÃ¡ PyTorch container jako zÃ¡klad
```

**KdyÅ¾ budete potÅ™ebovat NeMo, mÅ¯Å¾ete buildit Docker image nebo pouÅ¾Ã­t PyTorch container pÅ™Ã­mo.**

---

## ğŸ“„ Dokumentace vytvoÅ™enÃ¡

1. **`~/INSTALACE_SOUHRN.md`** - PÅ¯vodnÃ­ technickÃ½ souhrn
2. **`~/START_PYTORCH_FINETUNE.md`** - Krok za krokem prÅ¯vodce PyTorch fine-tuningem
3. **`~/START_LMSTUDIO.md`** - KompletnÃ­ nÃ¡vod pro LM Studio
4. **`~/KOMPLETNI_SOUHRN.md`** - Tento soubor (kompletnÃ­ pÅ™ehled)
5. **`~/run_pytorch_finetune.sh`** - RychlÃ½ spouÅ¡tÄ›cÃ­ script
6. **`~/run_lmstudio.sh`** - RychlÃ½ spouÅ¡tÄ›cÃ­ script pro LM Studio

---

## ğŸš€ Co mÅ¯Å¾ete dÄ›lat HNED TEÄ

### 1. Testovat RAPIDS
```bash
conda activate rapids-cuda13
python -c "
import cudf
df = cudf.DataFrame({'a': [1, 2, 3], 'b': [10, 20, 30]})
print(df)
print(f'SouÄet: {df[\"a\"].sum()}')
"
```

### 2. ZaÄÃ­t s PyTorch Fine-tuningem
```bash
# PÅ™eÄtÄ›te si nÃ¡vod
cat ~/START_PYTORCH_FINETUNE.md

# Nebo spusÅ¥te container
~/run_pytorch_finetune.sh
```

### 3. Prozkoumat NeMo pÅ™Ã­klady
```bash
cd ~/NeMo-Automodel/examples
ls -la
# Najdete pÅ™Ã­klady pro LLM a VLM fine-tuning
```

---

## âš™ï¸ SystÃ©movÃ© informace

**GPU:** NVIDIA GB10 (DGX Spark)
**CUDA:** 13.0
**Python:** 3.12.3
**Docker:** 28.3.3 âœ“
**Conda:** 25.9.1 âœ“

**VolnÃ© mÃ­sto:** 3.4TB

---

## ğŸ”— UÅ¾iteÄnÃ© odkazy

1. **NeMo Fine-tune:** https://build.nvidia.com/spark/nemo-fine-tune
2. **PyTorch Fine-tune:** https://build.nvidia.com/spark/pytorch-fine-tune
3. **NVFP4 Quantization:** https://build.nvidia.com/spark/nvfp4-quantization
4. **NIM LLM:** https://build.nvidia.com/spark/nim-llm
5. **CUDA-X Data Science:** https://build.nvidia.com/spark/cuda-x-data-science

---

## ğŸ’¡ Tipy a triky

### ARM64 Kompatibilita
NÄ›kterÃ© Python balÃ­Äky nemajÃ­ ARM64 wheels - pouÅ¾ijte Docker containery.

### Unified Memory Architecture (UMA)
DGX Spark sdÃ­lÃ­ pamÄ›Å¥ mezi GPU a CPU. PÅ™i problÃ©mech:
```bash
sudo sh -c 'sync; echo 3 > /proc/sys/vm/drop_caches'
```

### Docker bez sudo
```bash
sudo usermod -aG docker $USER
newgrp docker
```

### Hugging Face Token
Pro pÅ™Ã­stup k modelÅ¯m potÅ™ebujete token:
https://huggingface.co/settings/tokens

---

## ğŸ“Š Souhrn stavu

| NÃ¡stroj | Status | Velikost | PÅ™ipraveno |
|---------|--------|----------|------------|
| RAPIDS | âœ… FunkÄnÃ­ | conda env | ANO |
| PyTorch | âœ… PÅ™ipraven | 18GB | ANO |
| TensorRT | âœ… Hotovo | 15GB | ANO |
| LM Studio | â³ Stahuje se | 1GB | Za chvÃ­li |
| NeMo | âœ… NaklonovÃ¡n | repo | ANO (Docker) |
| Ollama | âœ… NainstalovÃ¡n | - | ANO (Å¾Ã¡dnÃ© modely) |

---

## ğŸ¯ DalÅ¡Ã­ kroky

1. âœ… **Otestovat RAPIDS** - Hotovo!
2. âœ… **PÅ™ipravit PyTorch** - Hotovo!
3. âœ… **StÃ¡hnout TensorRT** - Hotovo!
4. â³ **StÃ¡hnout LM Studio** - ProbÃ­hÃ¡ (~28%)
5. â³ **StÃ¡hnout LLM modely z Mac Mini M4** - ProbÃ­hÃ¡ (50%)
6. ğŸ”œ **ZaÄÃ­t s fine-tuningem nebo lokÃ¡lnÃ­mi LLM** - PÅ™ipraveno!

---

**VÅ¡e je pÅ™ipraveno k prÃ¡ci!** ğŸš€

Pokud mÃ¡te jakÃ©koliv otÃ¡zky nebo narazÃ­te na problÃ©my, podÃ­vejte se do pÅ™Ã­sluÅ¡nÃ½ch nÃ¡vodÅ¯ nebo dokumentace NVIDIA.
